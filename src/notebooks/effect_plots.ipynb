{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0182f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from statistics import median\n",
    "import numpy as np\n",
    "import functools as ft\n",
    "from scipy.stats import wilcoxon\n",
    "from VD_A import VD_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaa34809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_classes_stats(\n",
    "        output_csv,\n",
    "        search_budget,\n",
    "        compared_function,\n",
    "        columns_to_group, \n",
    "        score_metric):\n",
    "    \"\"\"\n",
    "    Get Wilcoxon and Vargha-Delaney statistics for all classes and return both significant and all classes along with their stats.\n",
    "    \"\"\"\n",
    "\n",
    "    res = pd.read_csv(output_csv)\n",
    "    configuration_ids = [\n",
    "        'weak_' + str(search_budget),\n",
    "        'branch_' + str(search_budget),\n",
    "        'default_' + str(search_budget)]\n",
    "    all_columns = columns_to_group + [score_metric]\n",
    "\n",
    "    # Configuration column name is the second in the columns_to_group list\n",
    "    config_column = columns_to_group[1]\n",
    "\n",
    "    # Sort by configuration\n",
    "    res = res.loc[:,all_columns]\n",
    "    result = res[res.apply(lambda row : row[config_column] in configuration_ids, axis=1)]\n",
    "\n",
    "    # \"weak\" groups\n",
    "    weak_result = result.loc[result[config_column] == 'weak_' + str(search_budget)]\n",
    "    weak_groups = weak_result.groupby(columns_to_group)[score_metric]\n",
    "    print(len(weak_result))\n",
    "\n",
    "    # \"compared\" groups\n",
    "    compared_func_result = result.loc[result[config_column] == str(compared_function) + '_' + str(search_budget)]\n",
    "    compared_func_groups = compared_func_result.groupby(columns_to_group)[score_metric]\n",
    "    print(len(compared_func_result))\n",
    "\n",
    "    # Create a dictionary with the 10 runs per class and the resulting branch coverage for the weak + branch fitness function\n",
    "    weak_classes = dict()\n",
    "    for name, group in weak_groups:\n",
    "        weak_classes[name] = group.astype(float).to_numpy()\n",
    "    print(len(weak_classes))\n",
    "\n",
    "    # Create a dictionary with the 10 runs per class and the resulting branch coverage for the compared fitness function\n",
    "    compared_func_classes = dict()\n",
    "    for name, group in compared_func_groups:\n",
    "        compared_func_classes[name] = group.astype(float).to_numpy()\n",
    "    print(len(compared_func_classes))\n",
    "\n",
    "    # If there are less than 10 runs for a class, pad the branch coverage with 0 \n",
    "    def pad(val1, val2):\n",
    "        if val1.shape[0] == val2.shape[0]:\n",
    "            return val1, val2\n",
    "        if val1.shape[0] < val2.shape[0]:\n",
    "            return np.pad(val1, [(0, val2.shape[0]-val1.shape[0])]), val2\n",
    "        else:\n",
    "            return val1, np.pad(val2, [(0, val1.shape[0]-val2.shape[0])])\n",
    "\n",
    "    # Calculate statistical significance per class\n",
    "    # Apply the Wilcoxon test for (weak_classes, compared_classes) per batch of 10 runs\n",
    "    # Apply A. Vargha and H. D. Delaney. per batch\n",
    "    # Filter out non-significant classes and classes with less than 'large' effect size\n",
    "    class_stats = dict()\n",
    "\n",
    "    for ((key1, val1), (key2, val2)) in zip(weak_classes.items(), compared_func_classes.items()):\n",
    "\n",
    "        val1, val2 = pad(val1, val2)\n",
    "\n",
    "        # If both weak and compared score metrics are equal, then flag with (-2,-2)\n",
    "        # Otherwise perform Wilcoxon and Vargha-Delaney\n",
    "        stats_p = (-2,-2) if (np.sum(np.subtract(val1, val2)) == 0) else wilcoxon(val1, val2)\n",
    "        vd = VD_A(val1.tolist(), val2.tolist())\n",
    "        class_stats[key1[0]] = (stats_p, vd)\n",
    "        # print(str(key1) + str(val1) + \", \"+ str(key2) + str(val2) + \" HAS P VALUE OF: \" + str(p))\n",
    "\n",
    "    significant_class_stats = dict()\n",
    "\n",
    "    # Filter classes with 'p' < 0.05 and a large effect size \n",
    "    for (key, ((stats, p), vd)) in class_stats.items():\n",
    "        if (p > -2 and p < 0.05):\n",
    "        # if (p > -2 and p < 0.05 and vd[1] == 'large' and (vd[0] == 0 or vd[0] == 1)):\n",
    "            significant_class_stats[key] = ((stats, p), vd) \n",
    "    \n",
    "    # Return statistically significant class stats & all classes stats\n",
    "    return significant_class_stats, class_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cccd2d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diverging Texts plot\n",
    "\n",
    "def plot_diverging_text(search_budget, compared_class, classes_with_stats, score_metric, sample_range=None):\n",
    "\n",
    "    df1 = pd.DataFrame.from_dict(classes_with_stats, orient='index')\n",
    "    df1.rename(columns = {0: 'wilcoxon', 1:'vd'}, inplace = True)\n",
    "\n",
    "    vd_df = df1.drop('wilcoxon', axis=1)\n",
    "    df2 = (vd_df.apply(lambda x: x[0], axis=1, result_type='expand')).drop([1], axis=1)\n",
    "    df2.rename(columns = {0: 'vd_estimate'}, inplace = True)\n",
    "    # df = df2.iloc[: 100]\n",
    "    df = df2\n",
    "    df.sort_values('vd_estimate', inplace=True)\n",
    "    \n",
    "    if sample_range:\n",
    "        df = df.iloc[sample_range[0]:sample_range[1]]\n",
    "\n",
    "    # Draw plot\n",
    "    plt.figure(figsize=(30,30), dpi= 80)\n",
    "    plt.hlines(y=df.index, xmin=0.5, xmax=df.vd_estimate)\n",
    "    for x, y, tex in zip(df.vd_estimate, df.index, df.vd_estimate):\n",
    "        t = plt.text(x, y, round(tex, 2), horizontalalignment='right' if x >= 0.5 else 'left', \n",
    "                     verticalalignment='bottom', fontdict={'color':'red' if x < 0.5 else 'green', 'size':18})\n",
    "\n",
    "    # Decorations    \n",
    "    plt.yticks(df.index, fontsize=12)\n",
    "    plt.title('Effect size per class (' + str(score_metric) + ') - bcwm vs ' + compared_class + ' - search budget ' + str(search_budget), fontdict={'size':20})\n",
    "    plt.grid(linestyle='--', alpha=0.5)\n",
    "    plt.xlim(-0.25, 1.25)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b6716ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3347\n",
      "3369\n",
      "336\n",
      "338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3145: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3347\n",
      "3339\n",
      "336\n",
      "335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3145: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3340\n",
      "3356\n",
      "336\n",
      "338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3145: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3340\n",
      "3284\n",
      "336\n",
      "333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3145: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3254\n",
      "3321\n",
      "334\n",
      "338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3145: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3254\n",
      "3121\n",
      "334\n",
      "329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3145: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3178\n",
      "3188\n",
      "319\n",
      "321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3145: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3178\n",
      "3169\n",
      "319\n",
      "318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3145: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/daniela/.local/lib/python3.8/site-packages/scipy/stats/_morestats.py:3159: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "def plot_for_budgets(search_budgets, score_metric_filename, columns_to_group, score_metric, sample_range=None):\n",
    "    \n",
    "    significant_classes_stats = {}\n",
    "    for search_budget in search_budgets:\n",
    "        key_budget = 'stats' + str(search_budget)\n",
    "\n",
    "        # Contains the coverage results per class from EvoSuite (e.g. score_metric_filename = \"res_data/results-60.csv\")\n",
    "        if ('mutation' not in score_metric_filename):\n",
    "            score_metric_filename = 'res_data/results-' + str(search_budget) + '.csv'\n",
    "        \n",
    "        # significant_classes_stats['stats60_fitness'][0][class][0] -> Wilcoxon results (tuple) for significant classes\n",
    "        # significant_classes_stats['stats60_fitness'][0][class][1] -> Vargha-Delaney results (tuple) for significant classes\n",
    "        # Use ['stats60_fitness'][1] for all classes stats and not only the significant ones\n",
    "        \n",
    "        # Contains statistically significant classes at [0] and all classes at [1]\n",
    "        # res_dict['stats60_branch'][0].items() contains pairs of type (class_name, p-value)\n",
    "        significant_classes_stats[str(key_budget + '_branch')] = get_significant_classes_stats(\n",
    "            score_metric_filename,\n",
    "            search_budget,\n",
    "            'branch',\n",
    "            columns_to_group,\n",
    "            score_metric)\n",
    "\n",
    "        significant_classes_stats[str(key_budget + '_default')] = get_significant_classes_stats(\n",
    "            score_metric_filename,\n",
    "            search_budget,\n",
    "            'default',\n",
    "            columns_to_group,\n",
    "            score_metric)\n",
    "\n",
    "\n",
    "        # plot_diverging_text(search_budget, 'branch', significant_classes_stats[str(key_budget + '_branch')][0], score_metric, sample_range)\n",
    "        # plot_diverging_text(search_budget, 'default', significant_classes_stats[str(key_budget + '_default')][0], score_metric, sample_range)\n",
    "\n",
    "    return significant_classes_stats\n",
    "\n",
    "# BRANCH COVERAGE\n",
    "search_budgets=[60, 180, 300]\n",
    "sample_range=None\n",
    "columns_to_group=['TARGET_CLASS', 'configuration_id', 'project.id']\n",
    "score_metric='BranchCoverage'\n",
    "score_metric_filename='res_data/results-'\n",
    "\n",
    "significant_classes_stats_coverage = plot_for_budgets(search_budgets, score_metric_filename, columns_to_group, score_metric, sample_range)\n",
    "\n",
    "# MUTATION SCORE\n",
    "search_budgets=[60]\n",
    "sample_range=None\n",
    "columns_to_group=['class', 'configuration', 'project']\n",
    "score_metric='mutation_score_percent'\n",
    "score_metric_filename='res_data/mutation_scores.csv'\n",
    "\n",
    "significant_classes_stats_mutation = plot_for_budgets(search_budgets, score_metric_filename, columns_to_group, score_metric, sample_range)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e3417db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- budget 60: \n",
      "branch: 228\n",
      "default: 213\n",
      "intersection: 182\n",
      "336\n",
      "---- budget 180: \n",
      "branch: 218\n",
      "default: 216\n",
      "intersection: 178\n",
      "336\n",
      "---- budget 300: \n",
      "branch: 275\n",
      "default: 200\n",
      "intersection: 178\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "\n",
    "classes_to_analyse_coverage_branch = []\n",
    "\n",
    "classes_to_analyse_coverage_branch60 = (list(significant_classes_stats_coverage['stats60_branch'][0].keys()))\n",
    "classes_to_analyse_coverage_branch180 = (list(significant_classes_stats_coverage['stats180_branch'][0].keys()))\n",
    "classes_to_analyse_coverage_branch300 = (list(significant_classes_stats_coverage['stats300_branch'][0].keys()))\n",
    "classes_to_analyse_coverage_branch = list(set(classes_to_analyse_coverage_branch60 + classes_to_analyse_coverage_branch180 + classes_to_analyse_coverage_branch300))\n",
    "# print(len(classes_to_analyse_coverage_branch))\n",
    "\n",
    "classes_to_analyse_coverage_default = []\n",
    "\n",
    "classes_to_analyse_coverage_default60 = (list(significant_classes_stats_coverage['stats60_default'][0].keys()))\n",
    "classes_to_analyse_coverage_default180 = (list(significant_classes_stats_coverage['stats180_default'][0].keys()))\n",
    "classes_to_analyse_coverage_default300 = (list(significant_classes_stats_coverage['stats300_default'][0].keys()))\n",
    "classes_to_analyse_coverage_default = list(set(classes_to_analyse_coverage_default60 + classes_to_analyse_coverage_default180 + classes_to_analyse_coverage_default300))\n",
    "# print(len(classes_to_analyse_coverage_default))\n",
    "\n",
    "classes_to_analyse_coverage = list(set(classes_to_analyse_coverage_branch + classes_to_analyse_coverage_default))\n",
    "\n",
    "print('---- budget 60: ')\n",
    "print('branch: ' + str(len(classes_to_analyse_coverage_branch60)))\n",
    "print('default: ' + str(len(classes_to_analyse_coverage_default60)))\n",
    "print('intersection: ' + str(len(intersection(classes_to_analyse_coverage_branch60, classes_to_analyse_coverage_default60))))\n",
    "print(len(significant_classes_stats_coverage['stats60_branch'][1]))\n",
    "\n",
    "print('---- budget 180: ')\n",
    "print('branch: ' + str(len(classes_to_analyse_coverage_branch180)))\n",
    "print('default: ' + str(len(classes_to_analyse_coverage_default180)))\n",
    "print('intersection: ' + str(len(intersection(classes_to_analyse_coverage_branch180, classes_to_analyse_coverage_default180))))\n",
    "print(len(significant_classes_stats_coverage['stats180_branch'][1]))\n",
    "\n",
    "print('---- budget 300: ')\n",
    "print('branch: ' + str(len(classes_to_analyse_coverage_branch300)))\n",
    "print('default: ' + str(len(classes_to_analyse_coverage_default300)))\n",
    "print('intersection: ' + str(len(intersection(classes_to_analyse_coverage_branch300, classes_to_analyse_coverage_default300))))\n",
    "print(len(significant_classes_stats_coverage['stats300_branch'][1]))\n",
    "\n",
    "# classes_to_analyse_coverage = dict()\n",
    "# classes_to_analyse_coverage['default60'] = significant_classes_stats_coverage['stats60_default'][0].keys()\n",
    "# classes_to_analyse_coverage['default180'] = significant_classes_stats_coverage['stats180_default'][0].keys()\n",
    "# classes_to_analyse_coverage['default300'] = significant_classes_stats_coverage['stats300_default'][0].keys()\n",
    "# classes_to_analyse_coverage = np.array(list(classes_to_analyse_coverage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3a8174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- budget 60: \n",
      "branch: 319\n",
      "default: 318\n",
      "intersection: 318\n",
      "319\n"
     ]
    }
   ],
   "source": [
    "classes_to_analyse_mutation_branch60 = list(significant_classes_stats_mutation['stats60_branch'][1].keys())\n",
    "classes_to_analyse_mutation_default60 = list(significant_classes_stats_mutation['stats60_default'][1].keys())\n",
    "classes_to_analyse_mutation = list(set(classes_to_analyse_mutation_branch60 + classes_to_analyse_mutation_default60))\n",
    "\n",
    "print('---- budget 60: ')\n",
    "print('branch: ' + str(len(classes_to_analyse_mutation_branch60)))\n",
    "print('default: ' + str(len(classes_to_analyse_mutation_default60)))\n",
    "print('intersection: ' + str(len(intersection(classes_to_analyse_mutation_branch60, classes_to_analyse_mutation_default60))))\n",
    "print(len(classes_to_analyse_mutation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d29f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
